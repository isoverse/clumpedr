---
title: "Using clumpedr: basic data analysis"
author: "Ilja J. Kocken"
date: 2019-11-13
output:
  rmarkdown::html_vignette:
    self_contained: no
vignette: >
  %\VignetteIndexEntry{Using clumpedr: basic data analysis}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  cache = TRUE,
  autodep = TRUE,
  collapse = TRUE,
  comment = "#>"
)
```

Once you have `clumpedr` installed (see the README), you can first load the libraries:

# load the packages that we use
```{r}
  # library(tidyverse)  # a few of the below and many more
  library(glue)      # optional, if you want to glue strings together
  library(dplyr)     # for pipes, mutate, summarise, etc.
  library(tidyr)     # for nesting/unnesting
  library(ggplot2)   # for plots!

  library(isoreader) # read in raw data
  library(clumpedr)  # this package! process clumped isotope data
```

# get your data from raw instrument data into R

## load data from a remote

First locate where you have your raw data files stored.

Here I show how I load data from a remote Windows samba server on my GNU/Linux
machine.

Of course you can also just copy your files and paste them in a folder you
desire.

```{r, eval = FALSE}
folderstr <- "/run/user/1000/gvfs/smb-share:server=geofile02.geo.uu.nl,share=geo-labs/@RawData"
# read all did files
dids <- iso_read_dual_inlet(glue("{folderstr}/253pluskiel/Raw Data/Kiel Raw Data"),
                            cache = FALSE,
                            discard_duplicates = FALSE,
                            parallel = TRUE)
```

It's nice to save a cache/backup as an R data structure file, which we can read
in much faster.

```{r, eval = FALSE}
iso_save(dids, "out/dids.di.rds")
```

## load from the cache

Once we have saved the r data storage (`.rds`) file, we can load it much faster
than the raw data.

```{r, eval = FALSE}
dids  <- iso_read_dual_inlet("out/dids.di.rds")
```

I've made some standard data available here so as to run the tests, or a single
did file for an ETH-3 standard.

See their documentation with the following code:
```{r, eval = FALSE}
?standards
?eth3
```

# process the data!

Clean up the metadata and append the mass spectrometer name. This function
parses integers, numbers, etc. so that all the types are correct.

```{r}
didinfo  <- standards %>%
  clean_did_info(masspec = "MOTU")
```

We save the file info separately, since we'll have to refer to it for some plots.

```{r}
stdinfo <- iso_get_file_info(didinfo)
```

This would also be the place to add potential fixes to typos in the file info
using `isoreader::iso_mutate_file_info()`.

## run the processing step-by-step

Note that normally, it's faster and smarter not to save the output of every
step as a separate tibble, but in this case we do it so that we can easily
inspect the results along the way. See the end of the vignette for the single
pipe.

### filter measurements of interest

First we filter out the measurements we want, based on the Method name.

We use a regular expression, or `regexp`. They are very useful ways of looking
for patterns in strings.

```{r}
filt <- didinfo %>%
  # we can subset to some files of interest (e.g., based on a regular expression)
  # in this case we subset to all the runs that have a "Clumped" method.
  iso_filter_files(grepl("Clumped.*met", Method))
```

### extract raw data

Then we extract the raw data. This gives it in a format where each row
is one cycle of either `standard` or `sample` gas, with initensities
44--49 as columns.

```{r}
rawd <- filt %>%
  # get all the raw data, per cycle from the dids
  iso_get_raw_data()
```

### disable failed cycles

This disables any cycles that have a sudden drop in pressure/intensity. With
the `genplot = TRUE` option, we tell it to create a default ggplot to inspect
which cycles have been disabled.

```{r}
disc <- rawd %>%
  disable_cycles(fac = 1.5, relative_to = "init", genplot = TRUE)
```

### HINT: look at plots interactively

Note that it is very nice to look at this plot---or any of the future
ones---interactively using `ggplotly`:

```{r, eval = FALSE}
plotly::toWebGL(plotly::ggplotly(dynamicTicks = TRUE))
```

This creates an interactive version of the last plot in your browser. The
`plot_base()` function assigns a lot of redundant aesthetics to the ggplot
object. They won't show in regular plots, but when you create an interactive
version and you hover over a datapoint, all of the metadata is displayed.

Note that we use the `toWebGL` wrapper to make it run smoother for plots with
many points.

### background correction

Do a very simple background correction.

```{r}
bgds <- disc %>%
  correct_backgrounds(factor = 0.82)
```

For a background correction based on background scans performed before each run
we have to get the raw scan data into R. Isoreader currently does not support
reading in the `.scn` files directly, so we import excel files with multiple
sheets using the packages `readxl` and `purrr`, with something like:

```{r, eval=FALSE}
    files <- c("file1.xlsx", "file2.xlsx", "file3.xlsx")
    tibble(filepath = files) %>%
      mutate(file = basename(files)) %>%
                                          # append sheet names
      mutate(sheet = map(filepath,
                         ~ excel_sheets(.x))) %>%
      unnest(cols = c(sheet)) %>%
      mutate(bg = map2(.x = filepath, .y = sheet,
                           .f = ~ read_excel(path = .x, sheet = .y,
                                             # specify these in advance for faster reading
                                             col_types = bgs_types,
                                             col_names = bgs_names,
                                             range = "A1:AR525")))
```

Processing the background scan files in this way is beyond the scope of this
vignette for now, since the functions that do the work are not generalized
enough to work for other set-ups.

### spread match

First we re-order the data into a wide format, where sample and reference gas
intensities are listed next to each other as separate columns using the
gather-unite-spread approach.

Then we compare reference gas to sample gas. With the `method="normal"`, this
would calculate the average of first and second cycles for the reference gas.
We can also use a work-in-progress linear interpolation (`method="linterp"`) to
match the mass 44 intensity of the reference gas to that of the sample gas and
apply this same shift to all the other masses. At present, it performs more
poorly than the regular calculation though, probably due to cycle elimination.

For example, we convert from the below:

| `file_id`      | type         | cycle | v44.mV | v45.mV | v46.mV | v47.mV | v54.mV |
| `"file_1.did"` | `"sample"`   | 1     | 1200   | 1100   | 1000   | 5000   | -302   |
| ...            | ...          | ...   | ...    | ...    | ...    | ...    | ...    |
| `"file_1.did"` | `"standard"` | 0     | 1300   | 1100   | 1000   | 5000   | -260   |
| `"file_1.did"` | `"standard"` | 1     | 1200   | 1120   | 1020   | 5020   | -230   |

to the following output:

| `file_id`      | `file_datetime`     | cycle | s44  | s45  | s46  | s47  | s54  | r44  | r45  | r46  | r47  | r54  |
| `"file_1.did"` | 2019-03-01 12:00:00 | 1     | 1200 | 1100 | 1000 | 5000 | -302 | 1250 | 1110 | 1010 | 5010 | -245 |


```{r}
sprd <- bgds %>%
  spread_match(method = "normal") # "linterp")
```
### extract reference gas d13C and d18O values

```{r}
refd <- sprd %>%
  append_ref_deltas(didinfo)
```
### calculate little delta's and clumped values

Now we can go to the bread and butter of clumpedr, delta calculations!

```{r}
dlts <- refd %>%
  delta_values(plot_info = stdinfo, genplot = TRUE)
```

### collapse cycles: calculate averages and standard deviations

```{r}
coll <- dlts %>%
  collapse_cycles(d18O_PDBCO2, d13C_PDB, D47_raw)
```

### append metadata

This just `left_join`s the metadata based on `file_id`, so that we can use it
for outlier removal etc.

```{r}
dati <- coll %>%
  add_info(stdinfo)
```

### remove outliers

Based on several criteria, we can get rid of outliers. This needs to happen
before the Empirical Reference Frame is calculated and applied.

```{r}
rout <- dati %>%
  unnest(cols = cycle_data) %>%
  remove_outliers(genplot = TRUE)
```

### empirical transfer function

```{r}
detf <- rout %>%
  empirical_transfer_function(session = Preparation, genplot = TRUE)
```

### acid fractionation factor
```{r}
daff <- detf %>%
  acid_fractionation()
```

### temperature calculation
```{r}
temp <- daff %>%
  temperature_calculation() %>%
  pipe_plot(plot_delta)
```

## plots and summary

We can create some summary plots, i.e. of the temperature per standard:

```{r}
# create a tibble that holds heights for text annotations
summ <- temp %>%
  group_by(broadid) %>%
  summarise(y = max(D47_final, na.rm = TRUE) + .05, n = n())

temp %>%
  plot_base(x = broadid, y = D47_final) +
  geom_violin(aes(group = broadid, fill = broadid), alpha = 0.2) +
  geom_jitter(width = .05, alpha = .6) +
  geom_text(aes(x = broadid, y = y, label = n), data = summ, inherit.aes = FALSE)
```

If you don't understand any of the steps, look at the function documentation
(e.g.: `?empirical_transfer_function`) or look at the source code (type the
function name without parentheses into the command line).

Enjoy!

Here are all the steps in one pipeline:

```{r}
stdinfo <- iso_get_file_info(clean_did_info(standards, "MOTU"))

standards %>%
  clean_did_info("MOTU") %>%
  iso_filter_files(grepl("Clumped.*met", Method)) %>%
  iso_get_raw_data() %>%
  disable_cycles(genplot = F) %>%
  correct_backgrounds(0.82) %>%
  spread_match() %>%
  append_ref_deltas(standards) %>%
  delta_values(plot_info = stdinfo, genplot = F) %>%
  collapse_cycles(d18O_PDBCO2, d13C_PDB, D47_raw) %>%
  add_info(stdinfo, genplot = F) %>%
  unnest(cols = cycle_data) %>%
  remove_outliers(genplot = F) %>%
  empirical_transfer_function(genplot = F) %>%
  acid_fractionation() %>%
  temperature_calculation()
```
